---
layout: ../../layouts/MarkdownPostLayout.astro
title: 'Nobody is Perfect'
pubDate: 2025-12-11
modDate: 2025-12-12
description: 'This is my creed page.'
author: 'Nao'
image:
    url: '/images/perfect.jpg'
    alt: "Nao's Creed Image"
tags: ["Profile", "Nao", "Creed"]
---

<br>

This time, I'd like to talk about my personal beliefs.<br>
I often say that nobody is perfect...


## Nobody is Perfect

<div class="box2">

<p>There is no such thing as a perfect human being</p>

<p>We are not machines.</p>

<p>There is no such thing as a perfect human being.</p>

<p>We cannot choose our genes or our upbringing, just as we could not choose our parents before we were born.</p>

<p>Our bodies are not designed to absolutely prevent disability, illness, or ageing.</p>

<p>If we could become perfect human beings, everyone would surely be a good person.</p>
And we know that everyone is not.

<p>That is precisely why,<br>

<p>In such a world, I wish to be a person who remembers kindness, rather than just what is right.</p>

</div>

### I'm the one who often says there's no such thing as a perfect person

<img src="/images/nobody_1.jpg" alt="Nao's profile picture" class="w-full" />

This is a tweet from 2023.

I don't recall why I wrote such a thing,

but I suppose my mind was racing when I was ill.

Well, never mind that.

---


### We all live under the premise that everyone makes mistakes.

**Therefore, neither your own words nor anyone else's are necessarily correct.**

Some of you might be thinking, “Well, that's obvious”.

However, psychological research shows that people make surprisingly irrational judgements based on prejudice and preconceptions.
This is known in psychology as “cognitive bias”.

Let me give an example.

There is a cognitive bias called the “authority bias”.

This is a cognitive bias where we tend to believe that something endorsed by an authoritative figure must be correct.

This was revealed in the Milgram experiment conducted in 1963.

It showed that when ordered by someone wielding immense power to inflict harm or perform cruel acts, between 60% and over 80% of people would comply with the orders, despite being tormented by their conscience.

Considering this, I believe it is better to be aware that humans are fundamentally weak creatures.

> **About the Milgram Experiment**: This is the famous experiment on ‘obedience to authority’ conducted by Yale University psychologist Stanley Milgram in 1963. In the experiment, subjects were assigned the role of “teacher” and instructed to administer electric shocks of increasing intensity to a “student” (actually a fellow experimenter) for each incorrect answer. Astonishingly, the results showed that 60 to 80 per cent of ordinary people complied with the instructions from the experimenter, an authority figure, continuing to administer shocks despite experiencing pangs of conscience and even when the subject cried out in pain. This experiment provides crucial psychological insights into why atrocities like the Holocaust during the Nazi era were possible.
I believe it is better to harbour a sense of crisis, thinking “I might become like this”, rather than thinking “I would never become like that”.

For it is precisely those who believe they cannot be deceived who are most likely to be deceived.

### The Dark Side of Justice Addiction

You may be familiar with the term “justice addiction”.

As the term suggests, it describes becoming so intoxicated by justice that one feels compelled to punish those who disrupt group rules.

This justice addiction stems from a bias that evil must be punished. It can escalate into bullying, potentially driving the victim to the point of death.

Many things in the world cannot be judged solely on a binary axis of right or wrong.

It is simplistic to label something as either right or wrong, or to dismiss what is not right as inherently evil.

Cult religions provide a clear example. Those who join such groups often become unable to listen to others' opinions because they are overly fixated on believing one particular thing is absolutely correct.

Even if something is correct, I believe it is also necessary to some extent to accept that whether others accept it is their own problem.

 (Of course, legal and ethical issues come into play, so the extent of tolerance depends on the specific case.)

### Three Things to Avoid Becoming Too Infused with Your Own Beliefs

To prevent becoming overly infused with the belief that one's own thoughts are correct,

I would like to propose three things.

---

1. **<span class="green2">Always question your own thoughts and increase opportunities to encounter opinions differing from your own. </span>**
2. **<span class="green2">Refrain from viewing things strictly through the lens of right or wrong; always leave room for them to be mere hypotheses. </span>**
3. **<span class="green2">Cultivate a degree of tolerance, recognising that even if others are mistaken, it is, to some extent, only human. </span>**

---

This applies equally when you yourself are mistaken.

Incidentally, as an aside, the book that prompted me to start questioning my own thoughts was
“99.9% is Hypothesis”.

I read it during my high school years and found it fascinating, enjoying how science seems to roll back and forth.
Others are different from oneself.

Others live by their own way of thinking.

Therefore, when someone speaks, they should do so accepting that the listener may not understand, taking into account the listener's interpretation, knowledge, and abilities.

Support what you believe to be correct with data.

Leaving room for doubt is also necessary.

On the other hand, for the listener,
rather than focusing on ‘who’ said it, don't take the ‘content of the statement’ at face value.

‘Is there any basis for this?’ ‘Can this truly be considered?’
while comparing it to their own internal answers.

Of course, I should say this is merely a hypothesis.

<br>

<span class="red">Because neither you nor I are perfect human beings. </span>

