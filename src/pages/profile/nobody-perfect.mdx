---
layout: ../../layouts/MarkdownPostLayout.astro
pageTitle: 'Nobody is Perfect'
pubDate: 2025-12-01
modDate: 2025-12-20
description: "This is Nao's creed page."
author: 'Nao'
image:
    url: '/images/perfect.jpg'
    alt: "Nao's profile image"
tags: ["profile", "Nao", "creed"]
githubRepoName: "nobody-perfect.mdx (GitHub Source)"
githubUrl: "https://github.com/naomina121/en.naomina121-astro/blob/main/src/pages/profile/nobody-perfect.mdx"
---

This time, I'd like to talk about my personal beliefs.<br />
I often say that nobody is perfect...

<div class="box2">

There is no such thing as a perfect human being

We are not machines.

There is no such thing as a perfect human being.

We cannot choose our genes or upbringing, just as we cannot choose our parents before we are born.

Our bodies are not designed to absolutely prevent disability, illness, or ageing.

If we could become perfect, everyone would be a good person.

And we know that's not the case for everyone.

That's precisely why,

in a world like this, I want to be someone who remembers kindness over being right.

</div>


### I'm the one who often says there's no such thing as a perfect person
<img src="/images/nobody_1.png" alt="Nao's profile picture" class="w-full" />
This is a tweet from 2023.
I don't recall why I wrote such a thing,
but I suppose my mind was racing when I was ill.
Well, never mind that.
---


### We all live under the premise that everyone makes mistakes.

**Therefore, neither your own words nor anyone else's are necessarily correct.**
Some of you might be thinking, “Well, that's obvious”.

However, psychological research shows that people make surprisingly irrational judgements based on prejudice and preconceptions.

This is known in psychology as “cognitive bias”.

Let me give an example.

There is a cognitive bias called the “authority bias”.

This is a cognitive bias where we tend to believe that something endorsed by an authoritative figure must be correct.

This was revealed in the Milgram experiment conducted in 1963.

It showed that when ordered by someone wielding immense power to inflict harm or perform cruel acts, between 60% and over 80% of people would comply with the orders, despite being tormented by their conscience.

Considering this, I believe it is better to be aware that humans are fundamentally weak creatures.

> **About the Milgram Experiment**: This is the famous experiment on ‘obedience to authority’ conducted by Yale University psychologist Stanley Milgram in 1963. In the experiment, subjects were assigned the role of “teacher” and instructed to administer electric shocks of increasing intensity to a “student” (actually a fellow experimenter) for each incorrect answer. Astonishingly, the results showed that 60 to 80 per cent of ordinary people complied with the instructions from the experimenter, an authority figure, continuing to administer shocks despite experiencing pangs of conscience and even when the subject cried out in pain. This experiment provides crucial psychological insights into why atrocities like the Holocaust during the Nazi era were possible.

I believe it is better to harbour a sense of crisis, thinking “I might become like this”, rather than thinking “I would never become like that”.

For it is precisely those who believe they cannot be deceived who are most likely to be deceived.

### The Dark Side of Justice Addiction

You may be familiar with the term “justice addiction”.

As the term suggests, it describes becoming so intoxicated by justice that one feels compelled to punish those who disrupt group rules.

This justice addiction stems from a bias that evil must be punished. It can escalate into bullying, potentially driving the victim to the point of death.

Many things in life cannot be judged solely on a binary axis of right or wrong.

It is simplistic to label something as either right or wrong, or to dismiss what is not right as inherently evil.

Cult religions provide a clear example. Those who join such groups often become unable to listen to others' opinions because they are overly fixated on believing one particular thing is absolutely correct.

Even if something is correct, I believe it is also necessary to some extent to accept that whether others accept it is their own problem. (Of course, legal and ethical issues come into play, so the extent of tolerance depends on the specific case.)

### Three Things to Avoid Becoming Overly Infused with Your Own Beliefs

To prevent one's own beliefs from becoming overly infused with a sense of righteousness,

I would like to propose three things.

---
1. **<span class="green2">Constantly question your own beliefs and increase opportunities to encounter opinions differing from your own. </span>**
2. **<span class="green2">Refrain from viewing things strictly through the lens of right or wrong; always leave room for them to be hypotheses. </span>**
3. **<span class="green2">Cultivate a degree of tolerance, accepting that even if others are wrong, it's somewhat inevitable given they are human. </span>**
---

This applies equally when you yourself are mistaken.

Incidentally, as an aside, the book that prompted me to start questioning my own thoughts was
“99.9% is Hypothesis”.

I read it during my high school years and found it fascinating, enjoying how science seems to roll back and forth.

Others are different from oneself.

Others live by their own thoughts.

Therefore, when speaking, one must accept that the listener may not understand, considering their interpretation, knowledge, and abilities.

Support what you believe to be correct with data.

Leaving room for doubt is also necessary.

On the other hand, for the listener,
rather than focusing on ‘who’ said it, do not take the ‘content of the statement’ at face value.

‘Is there evidence?’ ‘Can this truly be considered?’
while comparing it with their own internal answers.

Of course, I should say this is merely a hypothesis.

<br />

<p class="red">Because neither you nor I are perfect human beings. </p>
